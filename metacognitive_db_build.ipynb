{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T06:29:41.901918Z",
     "iopub.status.busy": "2026-01-13T06:29:41.901560Z",
     "iopub.status.idle": "2026-01-13T12:43:18.836785Z",
     "shell.execute_reply": "2026-01-13T12:43:18.835181Z",
     "shell.execute_reply.started": "2026-01-13T06:29:41.901857Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 06:29:44.380478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768285784.572022      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768285784.631638      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768285785.086341      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768285785.086377      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768285785.086380      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768285785.086382      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "METHOD DATABASE BUILDER\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¥ Loading questions from: /kaggle/input/rag-questions/selected_200_questions.json\n",
      "âœ… Loaded 200 questions\n",
      "ğŸ”§ Initializing Method Database Builder...\n",
      "\n",
      "ğŸ“¥ Loading reasoning model: ytu-ce-cosmos/Turkish-Gemma-9b-T1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969c9068e1eb4681a15f7e70a7c3baf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60d564ea0ec40638de4e77a7d3a1bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2787f73aaa4c3b8cb13cc9989e3626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971fc7e0e90e481daf7c5a2cc73a3a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/853 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f578c2f03249319915c50df9b2ddae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a938be776bc54c7688d2f1567d19ed46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7f16d0192a4008bc74f2a9de4af42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec931e59c13f47438c6bf7ef7e472241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7cece541984278aec0a88edfcae1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a017837ced4175ab47d0dd167f2acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c819db665349e59a05cde3d281d16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20626783566d4f7c8fe65182791e137d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/223 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f133818eaa504e739b68e21c64455e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2faba921ab94f6380cc2cc0778c7f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8864d362ec46ef95b2a29e0c185ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330e9d1d67a54e9c9c64143997b08fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34379f2fd650423f8f641e327cdc9202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b013d57fe9b4a72a18558932ef3797e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b2364740854bf997d2db1813ee6ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6165f9d744654cefac81bacae12513a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e0f26185084f62b20ffca3601fcb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8e22452bdc460798a4709be9d78ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477cc2975e664127add94e54b26ec9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embedding dimension: 384\n",
      "\n",
      "================================================================================\n",
      "Building database for prompt: metacognitive\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating methods (metacognitive):   0%|          | 1/200 [06:47<22:30:35, 407.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1:\n",
      "Solution: Define a variable ** Let x be the number of cans Tim has at first.\n",
      "After Jeff comes by, how many cans of soda does Tim have left? ** After Jeff comes by, Tim has x-6 cans left.\n",
      "How many more cans does Tim buy? ** Tim buys another (x-6)/2 cans.\n",
      "Write an equation ** x-6+(x-6)/2=24\n",
      "Simplify ** 2*x-12+x-6=48\n",
      "Simplify ** 3*x-18=48\n",
      "Simplify ** 3*x=66\n",
      "Simplify ** x=<<22=22>>22\n",
      "#### 22\n",
      "Method: Description of the thinking process and strategy (4-6 sentences)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating methods (metacognitive):   1%|          | 2/200 [07:55<11:25:22, 207.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 2:\n",
      "Solution: How many days are in a month? ** First find the total number of monthly commutes: 5 days/week * 4 weeks/month = <<5*4=20>>20 days/month\n",
      "How far is the commute? ** Then multiply the distance of the commute one way by the two ways: 21 miles * 2 = <<21*2=42>>42 miles\n",
      "How many miles are in the commute? ** Then multiply the number of commutes by the number of miles per commute: 42 miles/commute * 20 commutes = <<42*20=840>>840 miles\n",
      "How many gallons of gas does the car use? ** Then divide the number of miles by the car's gas mileage: 840 miles / 30 miles/gallon = <<840/30=28>>28 gallons\n",
      "How much does each person pay toward gas monthly? ** Then multiply that number by the cost of each gallon to find the total cost: 28 gallons * $2.50/gallon = $<<28*2.5=70>>70\n",
      "How much does each person pay toward gas monthly? ** Then divide the total cost by the number of friends to find the cost per person: $70 / 5 people = $<<70/5=14>>14/person\n",
      "#### 14\n",
      "Method: The solution method systematically decomposes the problem into key components: (1) Determine the total number of monthly commutes by multiplying daily frequency, weekly days, and weeks per month. (2) Calculate total monthly miles by multiplying round-trip distance (one-way distance doubled) by commutes per month. (3) Compute gas consumption using total miles and car efficiency. (4) Calculate total gas cost by multiplying gallons used by price per gallon. (5) Divide total cost by the number of friends to find per-person expense. Each step logically builds on the previous using given data and unit conversions, ensuring all variables are addressed before final division.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating methods (metacognitive):   2%|â–         | 3/200 [09:02<7:51:53, 143.73s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 3:\n",
      "Solution: Define a variable ** Let's say the number of fish that was in the tank before was x\n",
      "How many fish did you catch? ** If you caught 4 fewer fish than the number that was there, then you caught x-4\n",
      "Write an equation ** After adding x-4 fish into the tank, the tank now had 20 fish, meaning the total number of fish in the tank is x+x-4=20\n",
      "Combine like terms ** 2x=20+4\n",
      "How many fish were initially in the tank? ** The total number of fish that was initially in the tank is 2x=24\n",
      "How many fish were initially in the tank? ** Initially, there were x=24/2 fish in the tank\n",
      "Divide by 2 ** x=<<12=12>>12\n",
      "How many fish did you catch? ** If you caught 4 fewer fish than the number in my tank initially, you caught 12-4=<<12-4=8>>8 fish.\n",
      "#### 8\n",
      "Method: The problem requires identifying the number of fish added based on the current tank state and a relationship involving the initial tank. First, define a variable for the initial number of fish (x) to isolate the unknown. Interpret the phrase '4 fewer fish' as subtraction (x-4), representing the caught fish. Recognize that adding these fish to the tank means the current count (20) equals the sum of the original fish and the added fish. Formulate the equation: x + (x - 4) = 20. Solve the equation by combining like terms (2x - 4 = 20) and isolating x (2x = 24, x = 12). Finally, determine the added fish by subtracting the initial number from the current count (20 - 12 = 8) or directly from the caught fish (12 - 4 = 8).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating methods (metacognitive):   2%|â–         | 4/200 [10:00<5:58:25, 109.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 4:\n",
      "Solution: How much does the second bell weigh? ** First find the size of the second bell: 50 pounds * 2 = <<50*2=100>>100 pounds\n",
      "How much does the third bell weigh? ** Then find the size of the third bell: 100 pounds * 4 = <<100*4=400>>400 pounds\n",
      "How much bronze does Martin need total? ** Then add the amount of bronze used for each bell to find the total: 100 pounds + 400 pounds + 50 pounds = <<100+400+50=550>>550 pounds\n",
      "#### 550\n",
      "Method: The solution method involves a clear, step-by-step approach to decompose the problem. First, it identifies the relationship between the bells: the second bell is twice the size (and weight) of the first, and the third is four times the size of the second. The solver then calculates the size of each bell sequentially: using the first bell's size (50 pounds) to find the second (50 Ã— 2 = 100 pounds), and then using the second's size to find the third (100 Ã— 4 = 400 pounds). This maintains accuracy by avoiding direct scaling from the first to the third. Finally, the solver sums all sizes (50 + 100 + 400) to get the total bronze needed, recognizing that size directly translates to weight for the bronze casting. The strategy focuses on breaking down multiplicative relationships and sequential computation to ensure clarity and correctness.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating methods (metacognitive):   2%|â–         | 5/200 [15:13<9:54:38, 182.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 5:\n",
      "Solution: How many trees did Amiyah cut? ** The number of trees that Amiyah cut is 20/100*400 = <<20/100*400=80>>80\n",
      "How many trees are left on the farm? ** The number of trees remaining on the farm after she cut 80 trees is 400-80 = <<400-80=320>>320\n",
      "How many new trees did Amiyah plant? ** For every tree that Amiyah cut, she plants 5 new trees, and since she cut 80 trees, she planted 80*5 = <<80*5=400>>400 new trees.\n",
      "What is the total number of trees on the farm? ** The total number of trees on the farm is now 320+400 = <<320+400=720>>720 trees.\n",
      "#### 720\n",
      "Method: Ã–ncelikle, kesilen aÄŸaÃ§ sayÄ±sÄ±nÄ± hesaplamak iÃ§in baÅŸlangÄ±Ã§taki aÄŸaÃ§ sayÄ±sÄ±nÄ± ve kesilen yÃ¼zdesini kullanÄ±rÄ±m. Kesilen aÄŸaÃ§ sayÄ±sÄ± bulunduktan sonra, kesim iÅŸlemi sonrasÄ± Ã§iftlikte kalan aÄŸaÃ§ sayÄ±sÄ±nÄ± hesaplarÄ±m. Daha sonra, kesilen her aÄŸaÃ§ iÃ§in dikildiÄŸi belirtilen yeni aÄŸaÃ§ sayÄ±sÄ±nÄ± hesaplarÄ±m. Son olarak, kesim sonrasÄ± kalan aÄŸaÃ§lar ile dikilen yeni aÄŸaÃ§larÄ±n toplamÄ±nÄ± alarak Ã§iftlikteki son toplam aÄŸaÃ§ sayÄ±sÄ±nÄ± bulurum.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating methods (metacognitive): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [6:11:27<00:00, 111.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¢ Creating embeddings for 200 methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc973ece2fe4c5e8cfbf6ce5c87171c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Building FAISS index...\n",
      "âœ… Database built: 200 vectors indexed\n",
      "ğŸ’¾ Database saved to: method_databases/metacognitive\n",
      "   - FAISS index: method_databases/metacognitive/faiss_index.bin\n",
      "   - Metadata: method_databases/metacognitive/metadata.json\n",
      "   - Summary: method_databases/metacognitive/summary.json\n",
      "\n",
      "================================================================================\n",
      "âœ… ALL DATABASES BUILT SUCCESSFULLY\n",
      "ğŸ“‚ Output directory: method_databases\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from method_db_helper import MethodDatabaseBuilder\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "MODEL_ID = \"ytu-ce-cosmos/Turkish-Gemma-9b-T1\"\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "INPUT_FILE = Path(\"/kaggle/input/rag-questions/selected_200_questions.json\")\n",
    "OUTPUT_BASE_DIR = Path(\"method_databases\")\n",
    "OUTPUT_BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAX_NEW_TOKENS = 4096\n",
    "DTYPE = torch.bfloat16\n",
    "\n",
    "# =============================================================================\n",
    "# PROMPT TEMPLATES\n",
    "# =============================================================================\n",
    "PROMPTS = {  \n",
    "    \"metacognitive\": \"\"\"Analyze the following mathematical problem and its solution.\n",
    "\n",
    "Problem: {question}\n",
    "\n",
    "Solution: {solution}\n",
    "\n",
    "Task: Describe the thinking process and problem-solving strategy. Focus on \"what to think about\" rather than \"what to calculate\".\n",
    "\n",
    "Provide your answer as a JSON object with this exact format:\n",
    "{{\"method\": \"Description of the thinking process and strategy (4-6 sentences)\"}}\"\"\"\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"METHOD DATABASE BUILDER\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load questions\n",
    "    print(f\"\\nğŸ“¥ Loading questions from: {INPUT_FILE}\")\n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        questions_data = json.load(f)\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(questions_data)} questions\")\n",
    "    \n",
    "    # Initialize builder\n",
    "    builder = MethodDatabaseBuilder(MODEL_ID, EMBEDDING_MODEL)\n",
    "    \n",
    "    # Build database for each prompt\n",
    "    for prompt_name, prompt_template in PROMPTS.items():\n",
    "        try:\n",
    "            # Build\n",
    "            index, metadata = builder.build_database(\n",
    "                prompt_name, \n",
    "                prompt_template, \n",
    "                questions_data\n",
    "            )\n",
    "            \n",
    "            # Save\n",
    "            builder.save_database(\n",
    "                prompt_name, \n",
    "                index, \n",
    "                metadata, \n",
    "                OUTPUT_BASE_DIR\n",
    "            )\n",
    "            \n",
    "            # Cleanup\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Error building database for {prompt_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"âœ… ALL DATABASES BUILT SUCCESSFULLY\")\n",
    "    print(f\"ğŸ“‚ Output directory: {OUTPUT_BASE_DIR}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Final cleanup\n",
    "    del builder.model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9232965,
     "sourceId": 14455362,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
